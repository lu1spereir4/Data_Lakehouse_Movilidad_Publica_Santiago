# ğŸš‡ Data Lakehouse â€” Movilidad PÃºblica Santiago

![Python](https://img.shields.io/badge/Python-3.14-3776AB?style=flat&logo=python&logoColor=white)
![DuckDB](https://img.shields.io/badge/DuckDB-FFCC00?style=flat&logo=duckdb&logoColor=black)
![SQL Server](https://img.shields.io/badge/SQL_Server-CC2927?style=flat&logo=microsoftsqlserver&logoColor=white)
![Medallion](https://img.shields.io/badge/Architecture-Medallion-blueviolet?style=flat)
![Kimball](https://img.shields.io/badge/Modeling-Kimball_Star_Schema-0078D4?style=flat)
![Status](https://img.shields.io/badge/Status-En_Desarrollo-orange?style=flat)

> **ImplementaciÃ³n de un Data Lakehouse de alto rendimiento** diseÃ±ado para procesar, transformar y analizar **50.5 millones de registros** del transporte pÃºblico de Santiago. El proyecto muestra la transiciÃ³n desde datos crudos hacia un **Data Warehouse dimensional (Kimball)** optimizado para analÃ­tica, usando procesamiento eficiente en local (DuckDB/Parquet) y carga a SQL Server.

---

## ğŸ§­ Modelo Dimensional (vista general)

> **Tip:** Si vienes directo por el DW/modelado, esta es la secciÃ³n clave. 
> ğŸ“„ **[Lee la documentaciÃ³n detallada y justificaciÃ³n de decisiones arquitectÃ³nicas aquÃ­ â¡ï¸](movilidad_publicaStgo/models/README.md)**

![Constellation Model](movilidad_publicaStgo/models/constelar_model.png)

### ğŸ” Data Marts (diagramas por Ã¡rea temÃ¡tica)

SeparÃ© el DW en **Data Marts** para que el diseÃ±o sea legible (evitar un diagrama gigante con lÃ­neas cruzadas) y para que cada mart tenga un objetivo claro.

- **1) Trips & OD (Movilidad/Demanda de viajes)** Objetivo: OD, duraciÃ³n, transbordos, propÃ³sito, horas punta por viaje.  
  ğŸ‘‰ Ver diagrama: [data_mart_trips_od.png](movilidad_publicaStgo/models/data_mart_trips_od.png)

- **2) Trip Legs (Etapas dentro del viaje)** Objetivo: transbordos, secuencias BUSâ†’METRO, puntos de intercambio, carga por servicio por etapa.  
  ğŸ‘‰ Ver diagrama: [data_mart_trip_legs.png](movilidad_publicaStgo/models/data_mart_trip_legs.png)

- **3) Stages & Operations (OperaciÃ³n por validaciÃ³n)** Objetivo: servicio, modo, espera, bajadas detectadas, performance por paradero/servicio.  
  ğŸ‘‰ Ver diagrama: [data_mart_stages_operations.png](movilidad_publicaStgo/models/data_mart_stages_operations.png)

- **4) Network Demand (Demanda agregada por paradero/30m)** Objetivo: perfiles horarios de subidas promedio por paradero, modo y tipo de dÃ­a.  
  ğŸ‘‰ Ver diagrama: [data_mart_network_demand.png](movilidad_publicaStgo/models/data_mart_network_demand.png)

> Nota: Todos los marts comparten **dimensiones conformadas** (ej. `dim_date`, `dim_time_30m`, `dim_stop`), por lo que se pueden cruzar para anÃ¡lisis mÃ¡s completos.

---

## âš¡ MÃ©tricas del Proyecto

| Indicador | Valor |
|-----------|-------|
| ğŸ“¦ Registros procesados | **50,508,171** filas |
| ğŸ’¾ Volumen de datos raw | **~15.9 GB** |
| ğŸ“ Datasets integrados | 3 (viajes, etapas, subidas_30m) |
| ğŸ—“ï¸ PerÃ­odo cubierto | Semana 21â€“27 abril 2025 |
| ğŸ™ï¸ Fuente | DTPM â€” RED Movilidad Santiago |
| ğŸ”» ReducciÃ³n de columnas (viajes) | **100 â†’ 21 cols (ahorro 67%)** |

---

## ğŸ›ï¸ Arquitectura: Medallion

Este proyecto implementa la **Medallion Architecture**, el estÃ¡ndar de la industria para Data Lakehouses (usado por Databricks, Azure y AWS), adaptado a un entorno local de alto rendimiento.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA SOURCES                             â”‚
â”‚   ZIP + CSV.GZ (viajes, etapas)  â”‚  XLSB (subidas paradero)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                             â”‚
                    â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥‰ BRONZE â€” lake/raw/                                          â”‚
â”‚  Datos fuente sin modificar, particionados con Hive-style       â”‚
â”‚  dataset=<X>/year=YYYY/month=MM/cut=<periodo>/                  â”‚
â”‚  âœ“ ExtracciÃ³n automatizada  âœ“ _meta.json por particiÃ³n          â”‚
â”‚  âœ“ lake_catalog.json centralizado                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥ˆ SILVER â€” lake/processed/                           [WIP]    â”‚
â”‚  Limpieza Â· Tipado Â· NormalizaciÃ³n Â· SelecciÃ³n de columnas      â”‚
â”‚  Motor: DuckDB / Polars Â· Salida: Parquet                       â”‚
â”‚  âœ“ AnÃ¡lisis de calidad por columna (null_rate, dtype)           â”‚
â”‚  âœ“ CSVs slim generados (columnas de negocio)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥‡ GOLD â€” lake/curated/ + SQL Server DW              [WIP]     â”‚
â”‚  Star Schema (Kimball)  Â·  SQL Server                           â”‚
â”‚  fact_viajes Â· fact_etapas Â· dim_tiempo Â· dim_paradero          â”‚
â”‚  dim_servicio Â· dim_comuna Â· dim_periodo                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ Estructura del Repositorio

```
ğŸ“¦ Data_Lakehouse_Movilidad_PÃºblica_Santiago/
â”‚
â”œâ”€â”€ ğŸ“‚ data/                          # Fuentes originales (ZIPs, XLSB)
â”‚   â””â”€â”€ extracted/                    # Temporal â€” eliminable post-pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ lake/
â”‚   â”œâ”€â”€ lake_catalog.json             # CatÃ¡logo unificado de todos los metadatos
â”‚   â”œâ”€â”€ README.md                     # DocumentaciÃ³n tÃ©cnica del lake
â”‚   â”œâ”€â”€ raw/dtpm/                     # ğŸ¥‰ Bronze
â”‚   â”‚   â”œâ”€â”€ dataset=viajes/           #   3.6M filas/dÃ­a Ã— 7 dÃ­as
â”‚   â”‚   â”œâ”€â”€ dataset=etapas/           #   28.4M filas (semana completa)
â”‚   â”‚   â””â”€â”€ dataset=subidas_30m/      #   747K filas (promedio mensual)
â”‚   â”œâ”€â”€ processed/dtpm/               # ğŸ¥ˆ Silver â€” columnas slim + Parquet
â”‚   â””â”€â”€ curated/                      # ğŸ¥‡ Gold â€” Star Schema [WIP]
â”‚
â”œâ”€â”€ ğŸ“‚ models/                        # DDL del Star Schema en SQL Server
â”‚
â”œâ”€â”€ extract_data.py                   # Descomprime ZIP/GZ anidados
â”œâ”€â”€ build_lake.py                     # Construye estructura Hive + _meta.json
â”œâ”€â”€ build_catalog.py                  # Genera lake_catalog.json consolidado
â””â”€â”€ analyze_columns.py                # AnÃ¡lisis de calidad + CSV slim
```

---

## ğŸ”¬ Los Datos

Los datos provienen del **DTPM (Directorio de Transporte PÃºblico Metropolitano)**, publicados como datos abiertos. Combinan dos fuentes crÃ­ticas:

- ğŸ“¡ **GPS de la flota** â€” posiciÃ³n y tiempo de cada bus en operaciÃ³n
- ğŸ’³ **Transacciones Bip!** â€” cada validaciÃ³n de tarjeta en subida y bajada inferida

### Datasets

| Dataset | Granularidad | Filas | Columnas raw | DescripciÃ³n |
|---------|-------------|-------|--------------|-------------|
| `viajes` | 1 fila = 1 viaje completo | ~21.3M | 101 | Origen-destino, modos, tiempos, propÃ³sito del viaje |
| `etapas` | 1 fila = 1 validaciÃ³n Bip! | 28.4M | 35 | Detalle de cada tramo con coordenadas GPS |
| `subidas_30m` | Promedio por paradero/30min | 747K | 6 | Demanda agregada por parada, modo y tipo de dÃ­a |

---

## ğŸ§¹ Capa Silver â€” Decisiones de IngenierÃ­a

### Â¿Por quÃ© ETL y no ELT?

Las empresas modernas migran hacia **ELT** porque es mÃ¡s flexible: cargas los datos crudos al motor SQL (Snowflake, BigQuery, Redshift) y transformas ahÃ­ con SQL puro. Si una columna cambia o un analista necesita un campo nuevo, es una lÃ­nea de SQL, no re-ejecutar un pipeline Python con 50M de filas.

**Sin embargo, para este proyecto se optÃ³ por ETL** por razones deliberadas:

1. **ConsolidaciÃ³n de fundamentos** â€” El objetivo es dominar Python + SQL antes de abstraerlos con herramientas cloud.
2. **Restricciones de almacenamiento local** â€” 15.9 GB raw requieren una estrategia cuidadosa sin cloud storage (S3/ADLS).
3. **Escalabilidad futura planeada** â€” El diseÃ±o Hive-partitioned es compatible con migraciÃ³n directa a Spark/Databricks.

### Transformaciones planeadas (Silver)

```
RAW (todo texto, pipe-separated)
  â”‚
  â”œâ”€ Tipado estricto
  â”‚    â€¢ timestamps   â†’ DATETIME
  â”‚    â€¢ coordenadas  â†’ FLOAT (UTM 19S)
  â”‚    â€¢ contadores   â†’ INTEGER
  â”‚    â€¢ categorÃ­as   â†’ VARCHAR normalizado
  â”‚
  â”œâ”€ NormalizaciÃ³n de strings
  â”‚    â€¢ comunas: 'santiago' / 'Santiago' / 'SANTIAGO' â†’ 'SANTIAGO'
  â”‚    â€¢ modos: 'Bus' / 'BUS' â†’ 'BUS'
  â”‚
  â”œâ”€ Tratamiento de nulos (valor centinela "-")
  â”‚    â€¢ Bajada no registrada â†’ NULL (pÃ©rdida de seÃ±al GPS en tÃºnel)
  â”‚    â€¢ Sin bajada por evasiÃ³n â†’ flag separado
  â”‚    â€¢ Viajes sin destino â†’ conservados con flag, no eliminados
  â”‚    â””â”€â”€ DecisiÃ³n: los outliers son DATOS, no errores â€” el DTPM los documenta
  â”‚
  â””â”€ SelecciÃ³n de columnas (analyze_columns.py)
       â€¢ viajes:      101 â†’ 21 columnas  (ahorro 67% en tamaÃ±o)
       â€¢ etapas:       35 â†’ 24 columnas  (ahorro 37%)
       â€¢ subidas_30m:   6 â†’  6 columnas  (todas relevantes)
```

### Motor de procesamiento

| OpciÃ³n | RAM requerida | Velocidad | DecisiÃ³n |
|--------|-------------|-----------|----------|
| **DuckDB** | ~8 GB | âš¡âš¡âš¡âš¡ | âœ… Primera opciÃ³n |
| **Polars** | ~4 GB (streaming) | âš¡âš¡âš¡ | âœ… Fallback si RAM insuficiente |
| PySpark | Cluster | âš¡âš¡âš¡âš¡âš¡ | ğŸ”œ Futuro con S3 |

DuckDB puede leer Parquet/CSV directamente desde disco sin cargar todo en RAM, ejecutando SQL ANSI estÃ¡ndar. Los resultados se escriben en Parquet columnar para maximizar velocidad en la carga Gold.

---

## â­ Capa Gold â€” Star Schema (Kimball)

El modelo sigue la **metodologÃ­a Kimball** con dimensiones conformadas entre `fact_viajes` y `fact_etapas`, permitiendo anÃ¡lisis cruzado a cualquier nivel de granularidad.

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   dim_tiempo   â”‚
                    â”‚  PK: time_id   â”‚
                    â”‚  fecha, hora   â”‚
                    â”‚  periodo, tipo â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  dim_servicioâ”‚    â”‚  fact_viajes   â”‚    â”‚  dim_paradero  â”‚
â”‚  PK: srv_id  â”œâ”€â”€â”€â”€â”‚  grain: viaje  â”œâ”€â”€â”€â”€â”‚  PK: par_id    â”‚
â”‚  linea, modo â”‚    â”‚  n_etapas      â”‚    â”‚  codigo, nombreâ”‚
â”‚  operador    â”‚    â”‚  duracion_min  â”‚    â”‚  comuna, zona  â”‚
â”‚  contrato    â”‚    â”‚  dist_ruta_m   â”‚    â”‚  coord UTM     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  factor_exp    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  proposito     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  dim_comuna  â”‚            â”‚             â”‚  dim_periodo   â”‚
â”‚  PK: com_id  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  PK: per_id    â”‚
â”‚  nombre      â”œâ”€â”€â”€â”€â”‚  fact_etapas   â”œâ”€â”€â”€â”€â”‚  nombre        â”‚
â”‚  region      â”‚    â”‚  grain: etapa  â”‚    â”‚  hora_inicio   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  tiempo_etapa  â”‚    â”‚  hora_fin      â”‚
                    â”‚  espera_min    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  tiene_bajada  â”‚
                    â”‚  dist_ruta_m   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico

| CategorÃ­a | Herramienta | Uso |
|-----------|------------|-----|
| Lenguaje | Python 3.14 | Scripting, ETL, anÃ¡lisis |
| Procesamiento | DuckDB / Polars | TransformaciÃ³n Silver en memoria eficiente |
| Data Warehouse | SQL Server | Capa Gold, Star Schema |
| Formato columnar | Parquet | Almacenamiento intermedio Silver |
| Particionado | Hive-style | Compatibilidad Spark/Trino futura |
| Versionado | Git + GitHub | Control de versiones |
| CatalogaciÃ³n | JSON (_meta.json) | Linaje de datos por particiÃ³n |

---

## ğŸš€ Pipeline â€” CÃ³mo ejecutar

### Requisitos

```bash
pip install pyxlsb pandas duckdb polars pyarrow
```

### Paso a paso

```powershell
# 1. Extraer fuentes (ZIP â†’ CSV.GZ â†’ CSV)
python extract_data.py

# 2. Construir lake/raw/ con particionado Hive
python build_lake.py

# 3. Generar catÃ¡logo unificado
python build_catalog.py

# 4. Analizar columnas y generar CSVs slim
python analyze_columns.py

# 5. [WIP] TransformaciÃ³n Silver â†’ Parquet
# python transform_silver.py

# 6. [WIP] Carga Gold â†’ SQL Server
# python load_gold.py
```

---

## ğŸ“Š Preguntas de Negocio a Responder

El Star Schema estarÃ¡ optimizado para responder:

- ğŸ• **Â¿CuÃ¡les son los perÃ­odos de mayor demanda por modo de transporte?**
- ğŸ—ºï¸ **Â¿QuÃ© flujos origen-destino (comuna-comuna) concentran mÃ¡s viajes?**
- ğŸ”„ **Â¿CuÃ¡ntos transbordos promedio realiza un usuario segÃºn el perÃ­odo del dÃ­a?**
- â±ï¸ **Â¿CuÃ¡l es el tiempo promedio de espera en paradero por servicio y hora?**
- ğŸ“ **Â¿QuÃ© paraderos tienen mayor concentraciÃ³n de subidas en hora punta?**
- ğŸ¯ **Â¿CÃ³mo varÃ­a el propÃ³sito del viaje (trabajo/hogar/educaciÃ³n) por zona?**
- ğŸ“‰ **Â¿QuÃ© servicios presentan mayor tasa de bajada no registrada (pÃ©rdida GPS)?**

---

## ğŸ—ºï¸ Roadmap

- [x] **ExtracciÃ³n** â€” DescompresiÃ³n de ZIPs anidados y archivos `.csv.gz`
- [x] **Capa Bronze** â€” Particionado Hive-style + `_meta.json` por particiÃ³n
- [x] **CatÃ¡logo** â€” `lake_catalog.json` con linaje completo (50.5M filas, 15.9 GB)
- [x] **AnÃ¡lisis de columnas** â€” Null rate, dtype inferido, selecciÃ³n de negocio
- [x] **CSVs slim** â€” ReducciÃ³n de 101â†’21 columnas en viajes (ahorro 67%)
- [ ] **Capa Silver** â€” Tipado, normalizaciÃ³n, Parquet via DuckDB/Polars
- [ ] **DiseÃ±o DDL** â€” Star Schema en SQL Server
- [ ] **Carga Gold** â€” ETL desde Parquet â†’ SQL Server
- [ ] **ValidaciÃ³n** â€” Queries analÃ­ticas sobre el Star Schema
- [ ] **Escalabilidad** â€” MigraciÃ³n a PySpark + S3 para mÃºltiples meses

---

## ğŸ“ DocumentaciÃ³n Adicional

- [`lake/README.md`](lake/README.md) â€” CatÃ¡logo tÃ©cnico completo del lake (datasets, columnas, metadatos)
- [`lake/lake_catalog.json`](lake/lake_catalog.json) â€” CatÃ¡logo machine-readable

---

## ğŸ‘¤ Autor

Proyecto de portafolio desarrollado como parte de un roadmap de **Data Engineering**, con enfoque en arquitecturas de datos modernas, modelado dimensional y procesamiento de grandes volÃºmenes a nivel local antes de escalar a cloud.

> *"El transporte pÃºblico genera datos masivos cada segundo â€” este proyecto convierte ese caos en inteligencia accionable."*

